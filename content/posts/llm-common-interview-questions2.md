---
title: "大模型面试题-基础篇（2）"
description: "大模型面试题-基础篇（2）"
keywords: ["LLM", "面试"]
author: "Arkin"
date: 2025-08-07T17:45:10+08:00
lastmod: 2025-09-19T17:45:10+08:00
draft: false
tags: ["LLM", "面试", "大模型", "人工智能"]
categories: ["人工智能"]
aliases: []
image: "img/featured-image.jpg"
toc: true
readingTime: true
showWordCount: true
showDateUpdated: true
---

> 基础不牢，地动山摇。很多人在忙着开发大模型，却对最核心的概念理解不全。基础题，正是行业内经过验证的共识，是必须掌握的底层逻辑。吃透它，你才能在复杂应用中立于不败之地。

{{< katex >}}

## Q&A

- ### 1. LLMs 中，常用的预训练任务包括哪些？（LLMs 的训练目标是什么？）

  在进行模型的大规模预训练时，往往需要设计合适的自监督预训练任务，使得模型能够从海量无标注数据中学习到广泛的语义知识与世界知识。

  目前，常用的预训练任务主要分为三类，包括 **语言建模（Language Modeling，LM）**、**去除自编码（Denoising Autoencoding，DAE）**以及**混合去噪器（Mixture-of-Denoisers,，MoD）**。

  下图展示了语言建模和去噪自编码个字的输入与输出示例。

  ![image-20250923120242372](https://mr-lai.oss-cn-zhangjiakou.aliyuncs.com/macminim4image-20250923120242372.png)

  - **语言建模（Language Modeling，LM）**

    语言建模任务是目前绝大部分大语言模型广泛采用的预训练任务。该任务的核心在于“预测下一个词元”，并且经常被应用于训练基于解码器的大语言模型，例如 GPT-3 和 PaLM 等。

    形式化来说，给定一个词元序列 \\(u = u_1, …, u_T\\)，语言建模任务的目标定义为词元的预测任务：基于序列中当前位置之前的词元序列 \\(u_{<t}\\)，采用自回归的方式对于目标词元 \\(u_t\\) 进行预测。在训练过程中，模型通常根据以下的似然函数进行优化：
    $$
    L_{LM}(u) = \sum_{t=1}^{T} \log P(u_t \mid u_{<t})
    $$
    具体含义如下：

    - \\(u\\) 表示一个包含了 \\(T\\) 个单词或字的句子，具体来说就是一个序列。
    - \\(L_{LM}(u)\\) 表示语言建模对该句子的损失函数。
    - \\(P(u_t \mid u_{<t})\\) 表示在已知前 \\(t-1\\) 个词元的条件下，第 \\(t\\) 个词元 \\(u_t\\) 出现的概率。
    - \\(\\log P(u_t \mid u_{<t})\\) 表示该条件概率的对数。
    - 整个公式求和表示在序列中从 \\(t=1\\) 到 \\(T\\) 所有词的对数概率的总和。

    此外，从本质上看，基于语言建模的预训还可以看作是一种多任务学习过程。例如：

    - 在预测句子前缀“这部电影剧情饱满，演员表演得也很棒，非常好看”中的`好看`时，模型实际上在进行情感分析任务的语义学习。
    - 在预测句子前缀“小明有三块糖，给了小红两块糖，因此还剩下一块糖”中的`一块糖`时，则是在进行数学算术任务的语义学习。

    可以列举出来更多类似的例子，覆盖更广的任务范围。因此，基于大规模文本预料的预训练任务能够潜在地学习到解决众多任务的相关知识与能力。

    训练效率：**Prefix Decoder < Causal Decoder**

    - **Causal Decoder** 结构会在所有 token 上计算损失，而 **Prefix Decoder** 只会在输出上计算损失。

  - **去噪自编码（Denosising Autoencoding，DAE）**

    - 除了传统的语言建模任务外，去噪自编码任务是另一种常见的语言模型预训练任务，广泛用于 BERT、T5 等预训练语言模型中。
    - 在去噪自编码任务中，输入文本经过一系列随机替换或删除操作，形成损坏的文本 \\(\\tilde{u}\\)。模型的目标是根据这些损坏的文本恢复出被替换或删除的词元片段 \\(u\\)。去噪自编码的训练目标可以用以下数学公式表示：

    $$
    L_{DAE}(u) = \log P(u \mid \tilde{u})
    $$

    - **与语言建模相比，去噪自编码任务的实现更为复杂**，需要设定额外的优化策略，如词元替换策略、替换片段长度、替换词元比例等。这些策略的选择会直接影响模型的训练效果。尽管去噪自编码任务在许多预训练语言模型中得到了广泛应用，然而，相比于语言建模任务，目前完全使用去噪自编码进行预训练的纯语言模型却还较为有限。代表性的模型包括 FLAN-T5。

  - **混合去噪器（Mixture-of-Denoisers, MoD）**

    - 混合去噪器，通过将语言建模和去噪自编码的目标划分为不同类型的去噪任务，对于预训练任务进行了统一建模。

- ### 2. LLMs 中，涌现能力是什么？

  - 什么是“涌现能力”？

    - 等一个复杂系统由很多微小的个体构成，这些微小个体凑到一起，互相作用，当数量足够多时，在宏观层面上展现出微观个体无法解释的特殊现象，就可以称之为“涌现现象”。

    ![image-20250924182710505](https://mr-lai.oss-cn-zhangjiakou.aliyuncs.com/macminim4image-20250924182710505.png)
  - 在日常生活中也有一些涌现现象，比如雪花的形成、堵车、动物迁徙、涡流形成等。
  - 这里以雪花为例来解释：雪花的构成是水分子、水分子很小，但是大量的水分子如果在外界温度条件变化的前提下相互作用，在宏观层面就会形成一个很规律、很堆成、很美丽的雪花。

  #### 猜想一：任务的评价指标不够平滑

  - 一种猜想是因为很多任务的评价指标不够平滑，导致我们现在看到的涌现现象。

    ![image-20250924182733308](https://mr-lai.oss-cn-zhangjiakou.aliyuncs.com/macminim4image-20250924182733308.png)

  - 关于这一点，我们拿 Emoji_movie 任务来给出解释。Emoji_movie 任务时说输入 Emoji 图像，要求 LLM 给出完全正确的电影名称，只有一字不错才算正确，错一个字都算错。

  - 如上图所示，输入的 Emoji 是一个女孩的笑脸，后面跟着三张鱼类的图像，你可以猜猜这是什么电影。下面左侧的 2m 代表模型参数规模是 200万参数，以及对应模型给出的回答。可以看出，随着模型的规模不断增大至 128B 时，LLM 才能完全猜对电影名称，但是在模型到了 125m 和 4B 的时候，其实模型已经慢慢开始接近正确答案了。

    ![image-20250924182832292](https://mr-lai.oss-cn-zhangjiakou.aliyuncs.com/macminim4image-20250924182832292.png)

  - 如果评价指标要求很严格，要求一个不错才算对，那么 Emoji_movie 任务我们就会看到涌现现象的出现，如上图图左所示。但是，如果我们把问题形式换成多选题，就给出几个候选答案，让 LLM 选，那么随着模型的不断增大，任务效果在持续稳定变好，但涌现现象消失，如上图图右所示。这说明评价指标不够平滑，起码是一部分任务看到涌现现象的原因。

  #### 猜想二：复杂任务 vs 子任务

  - 展现出涌现任务有一个共性，就是任务往往是由多个子任务构成的复杂任务。

  - 也就是，最终任务过于复杂，如果仔细分析，可以看出它是由多个子任务构成，这时候，子任务效果往往随着模型增大，符合 Scaling Law，而最终任务则体现为涌现现象。

  - 这个其实好理解，比如我们假设某个任务 T 有5个子任务 Sub-T 构成，每个 Sub-T 随着模型增大，指标从 40% 提升到 60%，但是最终任务的指标只从1.1%提升到了 7%，也就是说宏观上看到了涌现现象，但是子任务效果其实是平滑增长的。

    ![image-20250924183256952](https://mr-lai.oss-cn-zhangjiakou.aliyuncs.com/macminim4image-20250924183256952.png)

  拿下国际象棋任务作为例子，如上图所示，让语言模型预测下一步，最终评价指标是只有“将”死才算赢。如果按“将死”评估（红线），发现随着模型增大，模型在缓慢上升，符合涌现的表现。若评估 LLM 合法移动（绿线），而在合法的移动步骤里进行正确选择才够最后“将死”是个子任务，所以其实这是比将死简单的一个子任务。我们看合法移动随着模型规模，效果持续上升。此时，我们是看不到涌现现象的。

  #### 总结

  - 关于涌现现象的能力猜想，目前主流猜想：

    - 任务的评价指标不够平滑
    - 复杂任务 vs 子任务

    *内容参考来源：张俊林老师《大语言模型的涌现能力：现象和解释》*

- ### 3. 什么是 Scaling Law，谈谈你对它的理解

  - #### 3.1 Scaling Law 的目标

    - Having a sense of the capabilities of a model before trainning can improve decisions around alignment, safety. and deployment.                         ——GPT4 Technical Report
    - 在训练之前了解模型的能力，以改善关于大模型的对齐、安全和部署的决定。  —— GPT4 技术报告

    ![image-20250924210440416](https://mr-lai.oss-cn-zhangjiakou.aliyuncs.com/macminim4image-20250924210440416.png)

    图片来自OpenAI gpt4 技术报告 https://cdn.openai.com/papers/gpt-4.pdf 

    图 1. GPT-4 和较小模型的性能表现。（在训练之前，就大致预测出了 GPT-4 的性能边界）

    衡量标准是 openAI 的内部代码库衍生的数据集上的最终损失。这个数据集包括了大量代表标记，并未包括在训练集中。我们选择观察损失，因为在不同训练计算量的情况下，损失通常比其他指标更稳定。

    虚线表示对较小模型（不包括 GPT-4）的幂律拟合；该拟合可以准确预测 GPT-4 的最终损失。横轴为训练计算量，并进行了标准化处理，使得 GPT-4 对应的值为1。

  - #### 3.2 Scaling Law 的定义

    - **用计算量、数据集规模和模型规模**，来预测模型最终能力。（通常以相对简单的函数形态，ex: Linear relationship）

    在大模型中，我们期望模型能够理解人类语言的一般规律，从而做出和人类相似的表达方式，通过使用大量的数据进行训练从而获得使模型学习到数据背后的一般规律。

    在训练预训练模型时，通常有两个可以提高大语言模型性能的选项：增加数据集大小和增加模型中的参数量。在此基础上，训练过程中还存在一个限制条件，即训练成本，比如 GPU 的数量和可用于训练的时间等。

    因此，大语言模型的预训练，通常伴随着训练的计算量、数据集规模和模型规模的三方权衡博弈。

    ![image-20250924212850132](https://mr-lai.oss-cn-zhangjiakou.aliyuncs.com/macminim4image-20250924212850132.png)

    但是具体，他们之间的博弈是如何展开的？

    是否可以通过 Scaling Laws 预测大模型在训练的计算量、数据集规模和模型规模这三个因素变动时，损失值的变？

    这种预测能帮助一些关键的设计决策，比如在固定资源预算下，匹配模型的最佳大小和数据大小，而无需进行及其昂贵的试错。

  - #### 3.3 OpenAI vs DeepMind 关于 Scaling Law 的观点

    - ##### 公司背景介绍

      - DeepMind

        DeepMind，成立于2010年并于2015年被谷歌收购，是 Alphabet Inc. 的子公司。该公司专注于开发能模仿人类学习和解决复杂问题能力的 AI 系统。作为 Alphabet Inc. 的一部分，DeepMind 在保持高度独立的同时，也在利用谷歌的强大能力推动 AI 研究的发展。

        DeepMind在技术上取得了显著成就，包括开发 AlphaGo，击败了世界围棋冠军李世石的 AI 系统，展示了深度强化学习和神经网络的潜力，开启了一个 AI 时代。

      - OpenAI

        在谷歌收购 DeepMind后，为了避免谷歌在 AI 领域形成垄断，埃隆 马斯克和其他科技行业人物于2015年决定创建 OpenAI。它作为一个有声望的非营利组织，致力于开发能够推动社会进步的 AI 技术。

        不同于 DeepMind 像一个精于解决棋盘复杂战术的大师，专注于解决哪些有明确规则和目标的难题，OpenAI 更像是一个擅长语言艺术的诗人，致力于让机器理解和生成自然的人类语言。

        从坚持初期被外界难以理解的 GPT 路线信仰，知道拥有1750亿参数的 GPT-3 问世，OpenAI展示了其在生成式模型上无以伦比的能力，引领了一个 AI 时代。

    - ##### OpenAI 关于 Scaling Law 的观点

      - 2020年，来自 OpenAI的Kaplan 等人的团队，在《Scaling Laws for NeuralLanguage Models》论文中首次提出模拟神经语言模型的模型性能（Loss）与模型大小、数据集大小和训练计算量的关系。该团队发现三者中任何一个因素受限时，Loss与其之间存在幂律关系。

        *【注：幂律指的是两个变量的一个变量与另一个变量的某个幂次成正比。如果体现在图表中，当两个轴都是对数时，图像呈现为直线】*

        ![image-20250924215647917](https://mr-lai.oss-cn-zhangjiakou.aliyuncs.com/macminim4image-20250924215647917.png)

        *图片来自 OpenAI 发表文章：Scaling Laws for Neural Language Models*

        *图 1 随着用于训练的计算量、数据集规模和模型规模的增加，语言建模性能平稳提升。为了获取最佳性能，必须将这三个因素同步扩大。当没有收到其他两个因素限制时，性能与每个因素之间呈幂律关系。*

        该团队的研究结论总结如下：

        1. 影响模型性能的三个要素之间，**每个参数都受到另外两个参数的影响。当没有其他两个瓶颈时，性能会急剧上升，影响程度为 计算量 > 参数 > 数据集大小**。
        2. 在固定计算预算下进行训练时，最佳性能可以通过训练参数量非常大的模型并在远离收敛前停止（Early Stopping）来实现。
        3. 更大的模型在样本效率方面表现更好，能以更少的优化步骤和使用更少的数据量达到相同的性能水平。在实际应用中，应该优先考虑训练较大的模型。

    - ##### DeepMind 关于 Scaling Law 的观点

      - 2022年，来自 DeepMind 的 Hoffmann 等人的团队，在《Trainning Compute-Optimal Large Language Models》提出了与 OpenAI 截然不同的观点。

        OpenAI 建议在计算预算增加了10倍的情况下，如果想保持效果，模型的大小应增加5倍，而训练 token 的数量仅需要增加 1.8倍。

        DeepMind 这支团队则认为模型大小和训练 token 的数量都应该按相等的比例进行扩展。该团队还暗示许多像 GPT-3 这样的千亿参数大语言模型实际上都过度参数化，也就是说它们的参数量超过了实现良好的语言理解所需，并训练不足。

        该团队的研究结论总结如下：

        1. 对于给定的 FLOP 预算，损失函数有明显的谷底值：

           a. 模型太小时，在较少数据上较大的模型将是一种改进；

           b. 模型太大时，在更多数据上训练的较小模型将是一种改进。

           **也就是说，在给定的计算量下，数据量和模型参数量之间的选择平衡存在一个最优解。**

        2. 在计算成本达到最优的情况下，模型大小和训练数据（token）的数量应该等比例进行缩放，即：**如果模型的大小加倍，那么训练数据的数量应该加倍。对于给定参数量的模型，最佳的训练数据集大小约为模型中参数量的20倍。比如，对于一个 7B 的模型，理想的训练数据集大小应该约为 140B tokens**。

        3. 大模型训练需要更加关注数据集的扩展，但是**只有数据是高质量的时候，更大数据集的益处才能体现出来**。

    - ##### 总结

      - Scaling Law 定义：
        - 用计算量、数据集规模和模型规模，来预测模型的最终能力。

      - OpenAI 关于 Scaling Law 的主要观点：
        - 三个要素之间，每个参数会受到另外两个参数的影响。当没有其他两个瓶颈时，性能会急剧上升，影响程度为**计算量 > 参数 > 数据集大小**。

      - DeepMind 关于 Scaling Law 的主要观点：
        - 三个要素之间，应该按相等的比例进行扩展。


  

## 总结

在这里写文章的总结部分。



## 相关链接

- [原文视频](https://www.bilibili.com/video/BV1E4bczRES9?spm_id_from=333.788.videopod.episodes&vd_source=baf08b4f56da32601c712e9657f34742&p=3)

---

*感谢阅读，欢迎交流与反馈。*

*我的邮箱📮 arkin-dev@qq.com（需要交流请发邮件）。*
